{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r'/Users/therendysuffren/Desktop/GCP Project/ServiceKey_GoogleCloud2.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Google Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r'/Users/therendysuffren/Desktop/GCP Project/ServiceKey_GoogleCloud2.json'\n",
    "storage_client = storage.Client()\n",
    "dir(storage_client)\n",
    "bucket_name = 'ts_bucket2'\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "bucket.location = 'US'\n",
    "storage_client.create_bucket(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(storage_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a New Bucket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/65/7fnhccpn1xg0d6sj8y3t7b380000gn/T/ipykernel_16812/894879367.py:3: DeprecationWarning: Assignment to 'Bucket.location' is deprecated, as it is only valid before the bucket is created. Instead, pass the location to `Bucket.create`.\n",
      "  bucket.location = 'US'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Bucket: ts_bucket2>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_name = 'ts_bucket2'\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "bucket.location = 'US'\n",
    "storage_client.create_bucket(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create json object in google cloud storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def create_json(json_object,filename):\n",
    "     # create a blob\n",
    "    blob = bucket.blob(filename)\n",
    "    # upload the blob \n",
    "    blob.upload_from_string(\n",
    "        data=json.dumps(json_object),\n",
    "        content_type='application/json'\n",
    "        )\n",
    "    result = filename + ' upload complete'\n",
    "    return {'response' : result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your object\n",
    "json_object = {\n",
    "    \"product\": {\n",
    "    \"id\": 1234567890,\n",
    "    \"title\": \"My Super Awesome Product\",\n",
    "    \"vendor\": \"Vendor Test\",\n",
    "    \"product_type\": \"Type Test\",\n",
    "    \"created_at\": \"2020-05-11T16:07:45-04:00\",\n",
    "    \"updated_at\": \"2020-05-26T14:32:09-04:00\",\n",
    "    \"options\": [\n",
    "      {\n",
    "        \"id\": 1234567890\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the filename of your json object\n",
    "filename = 'test.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'test.json upload complete'}\n"
     ]
    }
   ],
   "source": [
    "# run the function and pass the json_object\n",
    "print(create_json(json_object, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " read the JSON file directly from the file in GCS bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from smart_open import open\n",
    "import apache_beam as beam\n",
    "\n",
    "class ReadFile(beam.DoFn):\n",
    "\n",
    "    def __init__(self, input_path):\n",
    "        self.input_path = input_path\n",
    "\n",
    "    def start_bundle(self):\n",
    "        self.client = storage.Client()\n",
    "   \n",
    "    def process(self, something):\n",
    "        clear_data = []\n",
    "        with open(self.input_path) as fin:\n",
    "            for line in fin:\n",
    "                data = json.loads(line)\n",
    "                product = data.get('product')\n",
    "\n",
    "                if product and product.get('id'):\n",
    "                    product_id = str(product.get('id'))\n",
    "                    vendor = product.get('vendor')\n",
    "                    product_type = product.get('product_type')\n",
    "                    updated_at = product.get('updated_at')\n",
    "                    created_at = product.get('created_at')\n",
    "                    product_options = product.get('options')\n",
    "\n",
    "                    option_ids = []\n",
    "                    if product_options:\n",
    "                        for option in product_options:\n",
    "                            option_ids.append(option.get('id'))\n",
    "\n",
    "                    clear_data.append([product_id, vendor, product_type, updated_at, created_at, option_ids])\n",
    "\n",
    "        yield clear_data\n",
    "        #yeild clear_data passes the array we created to the next state of the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will get as input the cleared data and write the CSV file to the output path using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "class WriteCSVFIle(beam.DoFn):\n",
    "\n",
    "    def __init__(self, bucket_name):\n",
    "        self.bucket_name = bucket_name\n",
    "\n",
    "    def start_bundle(self):\n",
    "        self.client = storage.Client()\n",
    "\n",
    "    def process(self, mylist):\n",
    "        df = pd.DataFrame(mylist, columns={'product_id': str, 'vendor': str, 'product_type': str, 'updated_at': str, 'created_at': str, 'option_ids': str})\n",
    "\n",
    "        bucket = self.client.get_bucket(self.bucket_name)\n",
    "        bucket.blob(f\"csv_exports.csv\").upload_from_string(df.to_csv(index=False), 'text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import argparse\n",
    "\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.options.pipeline_options import SetupOptions\n",
    "from apache_beam.options.pipeline_options import GoogleCloudOptions\n",
    "from apache_beam.options.pipeline_options import StandardOptions\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataflowOptions(PipelineOptions):\n",
    "\n",
    "    @classmethod\n",
    "    def _add_argparse_args(cls, parser):\n",
    "        parser.add_argument('--input_path', type=str, default='gs://ts_bucket2/test.json')\n",
    "        parser.add_argument('--output_bucket', type=str, default='didi_dataflow_temp')\n",
    "\n",
    "\n",
    "\n",
    "    def run(argv=None):\n",
    "        parser = argparse.ArgumentParser()\n",
    "        known_args, pipeline_args = parser.parse_known_args(argv)\n",
    "\n",
    "        pipeline_options = PipelineOptions(pipeline_args)\n",
    "        dataflow_options = pipeline_options.view_as(DataflowOptions)\n",
    "\n",
    "        with beam.Pipeline(options=pipeline_options) as pipeline:\n",
    "            (pipeline\n",
    "            | 'Start' >> beam.Create([None])\n",
    "            | 'Read JSON' >> beam.ParDo(ReadFile(dataflow_options.input_path))\n",
    "            | 'Write CSV' >> beam.ParDo(WriteCSVFIle(dataflow_options.output_bucket))\n",
    "            )\n",
    "\n",
    "\n",
    "        if __name__ == '__main__':\n",
    "            logging.getLogger().setLevel(logging.INFO)\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 7: --setup_file: command not found\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'python DataflowTest.py \\\\\\n   --runner DataflowRunner \\\\\\n   --project cobalt-ripsaw-367515 \\\\\\n   --staging_location gs://ts_bucket2\\\\\\n   --temp_location gs://ts_bucket2 \\\\\\n   --template_location gs://ts_bucket2\\n   --setup_file /Users/therendysuffren/Desktop/GCP Project/setup.py\\\\\\n   --save_main_session True\\\\\\n'' returned non-zero exit status 127.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m/Users/therendysuffren/Desktop/GCP Project/demo.ipynb Cell 20'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/therendysuffren/Desktop/GCP%20Project/demo.ipynb#ch0000021?line=0'>1</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_cell_magic(\u001b[39m'\u001b[39;49m\u001b[39mbash\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mpython DataflowTest.py \u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m   --runner DataflowRunner \u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m   --project cobalt-ripsaw-367515 \u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m   --staging_location gs://ts_bucket2\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m   --temp_location gs://ts_bucket2 \u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m   --template_location gs://ts_bucket2\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m   --setup_file /Users/therendysuffren/Desktop/GCP Project/setup.py\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m   --save_main_session True\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2347\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/therendysuffren/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py?line=2344'>2345</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   <a href='file:///Users/therendysuffren/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py?line=2345'>2346</a>\u001b[0m     args \u001b[39m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> <a href='file:///Users/therendysuffren/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py?line=2346'>2347</a>\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/therendysuffren/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py?line=2347'>2348</a>\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/magics/script.py:153\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/therendysuffren/opt/anaconda3/lib/python3.9/site-packages/IPython/core/magics/script.py?line=150'>151</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/therendysuffren/opt/anaconda3/lib/python3.9/site-packages/IPython/core/magics/script.py?line=151'>152</a>\u001b[0m     line \u001b[39m=\u001b[39m script\n\u001b[0;32m--> <a href='file:///Users/therendysuffren/opt/anaconda3/lib/python3.9/site-packages/IPython/core/magics/script.py?line=152'>153</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshebang(line, cell)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/magics/script.py:305\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/therendysuffren/opt/anaconda3/lib/python3.9/site-packages/IPython/core/magics/script.py?line=299'>300</a>\u001b[0m \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39mraise_error \u001b[39mand\u001b[39;00m p\u001b[39m.\u001b[39mreturncode \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='file:///Users/therendysuffren/opt/anaconda3/lib/python3.9/site-packages/IPython/core/magics/script.py?line=300'>301</a>\u001b[0m     \u001b[39m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/therendysuffren/opt/anaconda3/lib/python3.9/site-packages/IPython/core/magics/script.py?line=301'>302</a>\u001b[0m     \u001b[39m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/therendysuffren/opt/anaconda3/lib/python3.9/site-packages/IPython/core/magics/script.py?line=302'>303</a>\u001b[0m     \u001b[39m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/therendysuffren/opt/anaconda3/lib/python3.9/site-packages/IPython/core/magics/script.py?line=303'>304</a>\u001b[0m     rc \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39mreturncode \u001b[39mor\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m9\u001b[39m\n\u001b[0;32m--> <a href='file:///Users/therendysuffren/opt/anaconda3/lib/python3.9/site-packages/IPython/core/magics/script.py?line=304'>305</a>\u001b[0m     \u001b[39mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'python DataflowTest.py \\\\\\n   --runner DataflowRunner \\\\\\n   --project cobalt-ripsaw-367515 \\\\\\n   --staging_location gs://ts_bucket2\\\\\\n   --temp_location gs://ts_bucket2 \\\\\\n   --template_location gs://ts_bucket2\\n   --setup_file /Users/therendysuffren/Desktop/GCP Project/setup.py\\\\\\n   --save_main_session True\\\\\\n'' returned non-zero exit status 127."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python DataflowTest.py \\\n",
    "   --runner DataflowRunner \\\n",
    "   --project cobalt-ripsaw-367515 \\\n",
    "   --staging_location gs://ts_bucket2\\\n",
    "   --temp_location gs://ts_bucket2 \\\n",
    "   --template_location gs://ts_bucket2\n",
    "   --setup_file /Users/therendysuffren/Desktop/GCP Project/setup.py\\\n",
    "   --save_main_session True\\"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "04ba2fb5210885d825f7910f8e5f1cde5b51431651d41f9e0fac69f93b51121c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
